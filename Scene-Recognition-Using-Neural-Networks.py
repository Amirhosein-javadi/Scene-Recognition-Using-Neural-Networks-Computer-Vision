# -*- coding: utf-8 -*-
"""Final_code.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_3BO8Pr8Mr9N3IFuE4UnH6xlyom_32bz
"""

# !unzip '/content/drive/MyDrive/Data.zip'
# !unzip '/content/drive/MyDrive/Augmented_Data.zip'


import cv2
import numpy as np
import skimage
import glob
import math 

def Rotate(img,teta):
    R = np.zeros([3,3])
    R[2][2] =1
    R[0][0] = math.cos(teta)
    R[1][1] = math.cos(teta)
    R[0][1] = -math.sin(teta)
    R[1][0] = math.sin(teta)
    warp_im = cv2.warpPerspective(img,R,(img.shape[1],img.shape[0]))
    return warp_im

def Enhancement(img,y):
    enhancement_im = np.zeros_like(img)
    enhancement_im = 255 * (img/255)**y
    return enhancement_im

def Zoom(img,scale):
    row,col = img.shape
    zoom_im = np.zeros_like(img)
    if scale<1 :
       smaller = cv2.resize(img,(0, 0),fx=scale,fy=scale,interpolation=cv2.INTER_AREA) 
       s_row,s_col = smaller.shape
       zoom_im [row//2-s_row//2:row//2-s_row//2+s_row,col//2-s_col//2:col//2-s_col//2+s_col] = smaller 
    elif scale>1 :
       bigger = cv2.resize(img,(0, 0),fx=scale,fy=scale,interpolation=cv2.INTER_LINEAR) 
       s_row,s_col = bigger.shape
       zoom_im = bigger[s_row//2-row//2:s_row//2-row//2+row,s_col//2-col//2:s_col//2-col//2+col]
    return zoom_im

def Augmentation(img,folder,counter):
    file = folder + f'{counter}.jpg'
    cv2.imwrite(file,cv2.resize(img,(227, 227),interpolation=cv2.INTER_AREA)) 
    counter += 1
    Flip = cv2.flip(img, 1)
    file = folder + f'{counter}.jpg'
    cv2.imwrite(file,cv2.resize(Flip,(227, 227),interpolation=cv2.INTER_AREA)) 
    counter += 1    
    # Rotation
    teta = (2/180)*math.pi
    Warp_Im = Rotate(img,teta)
    file = folder + f'{counter}.jpg'
    cv2.imwrite(file,cv2.resize(Warp_Im,(227, 227),interpolation=cv2.INTER_AREA)) 
    counter += 1
    teta = (4/180)*math.pi
    Warp_Im = Rotate(img,teta)
    file = folder + f'{counter}.jpg'
    cv2.imwrite(file,cv2.resize(Warp_Im,(227, 227),interpolation=cv2.INTER_AREA)) 
    counter += 1
    teta = (-2/180)*math.pi
    Warp_Im = Rotate(img,teta)
    file = folder + f'{counter}.jpg'
    cv2.imwrite(file,cv2.resize(Warp_Im,(227, 227),interpolation=cv2.INTER_AREA)) 
    counter += 1
    teta = (-4/180)*math.pi
    Warp_Im = Rotate(img,teta)
    file = folder + f'{counter}.jpg'
    cv2.imwrite(file,cv2.resize(Warp_Im,(227, 227),interpolation=cv2.INTER_AREA)) 
    counter += 1   
    # Rotation  Flip  
    teta = (2/180)*math.pi
    Warp_Im = Rotate(Flip,teta)
    file = folder + f'{counter}.jpg'
    cv2.imwrite(file,cv2.resize(Warp_Im,(227, 227),interpolation=cv2.INTER_AREA)) 
    counter += 1
    teta = (4/180)*math.pi
    Warp_Im = Rotate(Flip,teta)
    file = folder + f'{counter}.jpg'
    cv2.imwrite(file,cv2.resize(Warp_Im,(227, 227),interpolation=cv2.INTER_AREA)) 
    counter += 1
    teta = (-2/180)*math.pi
    Warp_Im = Rotate(Flip,teta)
    file = folder + f'{counter}.jpg'
    cv2.imwrite(file,cv2.resize(Warp_Im,(227, 227),interpolation=cv2.INTER_AREA)) 
    counter += 1
    teta = (-4/180)*math.pi
    Warp_Im = Rotate(Flip,teta)
    file = folder + f'{counter}.jpg'
    cv2.imwrite(file,cv2.resize(Warp_Im,(227, 227),interpolation=cv2.INTER_AREA)) 
    counter += 1  
    # Darkening
    Enhancement_Im = Enhancement(img,1.1)
    file = folder + f'{counter}.jpg'
    cv2.imwrite(file,cv2.resize(Enhancement_Im,(227, 227),interpolation=cv2.INTER_AREA)) 
    counter += 1       
    Enhancement_Im = Enhancement(img,1.2)
    file = folder + f'{counter}.jpg'
    cv2.imwrite(file,cv2.resize(Enhancement_Im,(227, 227),interpolation=cv2.INTER_AREA)) 
    counter += 1 
    # Brightning
    Enhancement_Im = Enhancement(img,0.9)
    file = folder + f'{counter}.jpg'
    cv2.imwrite(file,cv2.resize(Enhancement_Im,(227, 227),interpolation=cv2.INTER_AREA)) 
    counter += 1    
    Enhancement_Im = Enhancement(img,0.8)
    file = folder + f'{counter}.jpg'
    cv2.imwrite(file,cv2.resize(Enhancement_Im,(227, 227),interpolation=cv2.INTER_AREA)) 
    counter += 1  
    # Zoom_in
    Zoom_Im = Zoom(img,1.1)
    file = folder + f'{counter}.jpg'
    cv2.imwrite(file,cv2.resize(Zoom_Im,(227, 227),interpolation=cv2.INTER_AREA))     
    counter += 1     
    Zoom_Im = Zoom(img,1.2)
    file = folder + f'{counter}.jpg'
    cv2.imwrite(file,cv2.resize(Zoom_Im,(227, 227),interpolation=cv2.INTER_AREA))     
    counter += 1   
    # Zoom_out
    Zoom_Im = Zoom(img,0.9)
    file = folder + f'{counter}.jpg'
    cv2.imwrite(file,cv2.resize(Zoom_Im,(227, 227),interpolation=cv2.INTER_AREA))     
    counter += 1     
    Zoom_Im = Zoom(img,0.8)
    file = folder + f'{counter}.jpg'
    cv2.imwrite(file,cv2.resize(Zoom_Im,(227, 227),interpolation=cv2.INTER_AREA))     
    counter += 1       
    return counter


Data_Type = {0:"Test",
             1:"Train"}

Data_Class={0:"Bedroom",
            1:"Coast",
            2:"Forest",
            3:"Highway",
            4:"Industrial",
            5:"Inside_City",
            6:"Kitchen",
            7:"Livingroom",
            8:"Mountain",
            9:"Office",
            10:"Open_Country",
            11:"Store",
            12:"Street",
            13:"Suburb",
            14:"Tall_Building"}   

counter = 0
for i in range(2):
    for j in range(15):
        Source_Folder = '/content/Data/' + Data_Type[i] + '/' + Data_Class[j]
        Target_Folder = '/content/Augmented_Data/' + Data_Type[i] + '/' + Data_Class[j]+ "/"
        Files = glob.glob(f'{Source_Folder}/*.jpg')
        for Pics in Files:
            Img = cv2.imread(Pics,0)
            counter = Augmentation(Img,Target_Folder,counter)
        counter = 0

"""Section 1"""

import tensorflow as tf
tf.config.experimental.set_memory_growth(tf.config.list_physical_devices('GPU')[0],True)
import numpy as np
from keras import initializers
from keras import layers,callbacks
from keras.callbacks import ModelCheckpoint
from keras.layers import Input, Dense, Activation,BatchNormalization, Flatten, Conv2D, MaxPooling2D, Dropout
from keras.models import Model
from keras.preprocessing import image
from keras.optimizers import SGD
from keras.preprocessing.image import ImageDataGenerator
from keras import metrics
from keras.metrics import SparseTopKCategoricalAccuracy 
import keras.backend as K
K.set_image_data_format("channels_last")
import glob 
import matplotlib.pyplot as plt

def True_val(File):
  counter = 0 ;
  true_pred = np.zeros([1,1])
  folders = glob.glob(f'{File}/*')
  for folder in folders:
    num_of_classes = np.size(glob.glob(f'{folder}/*.jpg'))
    val = np.ones([num_of_classes,1])*counter
    true_pred = np.concatenate((true_pred,val), axis=0)
    counter += 1
  true_pred = np.delete(true_pred,0,axis=0)
  return true_pred

def plot_func(y1,y2,max_iter,plt_file,plt_type,plt_title):
  x = np.array(range(1,max_iter+1,jump))
  plt.plot(x, y1, label = f'Test {plt_type}' , color='red', marker='o', markerfacecolor='red', markersize=5)
  plt.plot(x, y2, label = f'Train {plt_type}', color='blue' , marker='o', markerfacecolor='blue', markersize=5)
  plt.xlabel('epoch')
  plt.ylabel(f'{plt_type}')
  plt.title(f'{plt_title}')
  if plt_type == 'Accuracy':
    plt.ylim(0, 1)
  plt.legend()
  plt.grid()
  plt.show()
  plt.savefig(plt_file)
  return

def AlexNet():
  tf.config.experimental.list_logical_devices('GPU')
  tf.debugging.set_log_device_placement(True)
  with tf.device(tf.test.gpu_device_name()):
      X_input = Input((227,227,3))
      # Conv layer 1
      X = Conv2D(96,(11,11), strides=4, name="Conv0", kernel_initializer=initializers.GlorotUniform())(X_input)
      X = BatchNormalization(axis=3, name="Bn0")(X)
      X = Activation('relu')(X)
      X = MaxPooling2D((4,4), strides=4, name='Max0')(X)
      # X = Dropout(0.5)(X)
      # Fully connected layer 1
      X = Flatten()(X)
      X = Dense(4096, activation='relu', name="Fc0", kernel_initializer=initializers.GlorotUniform())(X)
      X = Dropout(0.5)(X)
      # Fully connected layer 2
      X = Dense(15,activation='softmax', name='Fc1', kernel_initializer=initializers.GlorotUniform())(X)
      opt = SGD(learning_rate=0.001 , momentum=0.97)
      model = Model(inputs=X_input,outputs=X, name='AlexNet')
      model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])
      return model

alex = AlexNet()
Train_Datagen = ImageDataGenerator(rescale=1./255)
Train_Path = '/content/Augmented_Data/Train'
Train = Train_Datagen.flow_from_directory(Train_Path, target_size=(227,227), class_mode='categorical', batch_size=256)	
Test_Datagen = ImageDataGenerator(rescale=1./255)
Test_Path = '/content/Augmented_Data/Test'
Test = Test_Datagen.flow_from_directory(Test_Path, target_size=(227,227), class_mode='categorical', batch_size=256)
y_pred_test = True_val('/content/Augmented_Data/Test/')
y_pred_train = True_val('/content/Augmented_Data/Train/')
max_iter = 41
jump = 3
Test_Loss_Top1 = np.zeros((max_iter-1)//jump+1)
Test_Accuracy_Top1 = np.zeros((max_iter-1)//jump+1)
Train_Loss_Top1 = np.zeros((max_iter-1)//jump+1)
Train_Accuracy_Top1 = np.zeros((max_iter-1)//jump+1)
Test_Accuracy_Top5 = np.zeros((max_iter-1)//jump+1)
Train_Accuracy_Top5 = np.zeros((max_iter-1)//jump+1)
m = SparseTopKCategoricalAccuracy(k=5)

for k in range(1,max_iter+1,jump):
  with tf.device(tf.test.gpu_device_name()):
    alex.fit(Train,epochs=k)
    Train_Top1 = alex.evaluate(Train)
    Train_Loss_Top1[(k-1)//jump]=Train_Top1[0]
    Train_Accuracy_Top1[(k-1)//jump]=Train_Top1[1]
    Test_Top1 = alex.evaluate(Test)
    Test_Loss_Top1[(k-1)//jump]=Test_Top1[0]
    Test_Accuracy_Top1[(k-1)//jump]=Test_Top1[1]
    #Train_Top5 = alex.predict(Train)
    #m.reset_states()
    #m.update_state(y_pred_train,Train_Top5) 
    #Train_Accuracy_Top5[(k-1)//jump] = m.result().numpy()
    #Test_Top5 = alex.predict(Test)
    #m.reset_states()
    #m.update_state(y_pred_test,Test_Top5) 
    #Test_Accuracy_Top5[(k-1)//jump] = m.result().numpy()    
    #print(Test_Accuracy_Top1)
    #print(Test_Accuracy_Top5)
    #print(Test_Loss_Top1)
    #print(Train_Accuracy_Top1)
    #print(Train_Accuracy_Top5)
    #print(Train_Loss_Top1)

plot_func(Test_Accuracy_Top1,Train_Accuracy_Top1,max_iter,'/content/Accuracy_top1.png','Accuracy',"Top-1")
#plot_func(Test_Accuracy_Top5,Train_Accuracy_Top5,max_iter,'/content/Accuracy_top5.png','Accuracy',"Top-5")
plot_func(Test_Loss_Top1,Train_Loss_Top1,max_iter,'/content/Loss_top1.png','Loss',"Top-1")

"""Section 2"""

import tensorflow as tf
tf.config.experimental.set_memory_growth(tf.config.list_physical_devices('GPU')[0],True)
import numpy as np
from keras import initializers
from keras import layers,callbacks
from keras.callbacks import ModelCheckpoint
from keras.layers import Input, Dense, Activation,BatchNormalization, Flatten, Conv2D, MaxPooling2D, Dropout
from keras.models import Model
from keras.preprocessing import image
from keras.optimizers import SGD
from keras.preprocessing.image import ImageDataGenerator
from keras import metrics
from keras.metrics import SparseTopKCategoricalAccuracy 
import keras.backend as K
K.set_image_data_format("channels_last")
import glob 
import matplotlib.pyplot as plt

def True_val(File):
  counter = 0 ;
  true_pred = np.zeros([1,1])
  folders = glob.glob(f'{File}/*')
  for folder in folders:
    num_of_classes = np.size(glob.glob(f'{folder}/*.jpg'))
    val = np.ones([num_of_classes,1])*counter
    true_pred = np.concatenate((true_pred,val), axis=0)
    counter += 1
  true_pred = np.delete(true_pred,0,axis=0)
  return true_pred

def plot_func(y1,y2,max_iter,plt_file,plt_type,plt_title):
  x = np.array(range(1,max_iter+1,jump))
  plt.plot(x, y1, label = f'Test {plt_type}' , color='red', marker='o', markerfacecolor='red', markersize=5)
  plt.plot(x, y2, label = f'Train {plt_type}', color='blue' , marker='o', markerfacecolor='blue', markersize=5)
  plt.xlabel('epoch')
  plt.ylabel(f'{plt_type}')
  plt.title(f'{plt_title}')
  if plt_type == 'Accuracy':
    plt.ylim(0, 1)
  plt.legend()
  plt.grid()
  plt.show()
  plt.savefig(plt_file)
  return

def AlexNet():
  tf.config.experimental.list_logical_devices('GPU')
  tf.debugging.set_log_device_placement(True)
  with tf.device(tf.test.gpu_device_name()):
      X_input = Input((227,227,3))
      # Conv layer 0
      X = Conv2D(96,(11,11), strides=4, name="Conv0", kernel_initializer=initializers.GlorotUniform())(X_input)
      X = BatchNormalization(axis=3, name="Bn0")(X)
      X = Activation('relu')(X)
      X = MaxPooling2D((3,3), strides=2, name='max0')(X)
      X = Dropout(0.5)(X)
      # Conv layer 1
      X = Conv2D(256,(5,5), padding='same', name='Conv1', kernel_initializer=initializers.GlorotUniform())(X)
      X = BatchNormalization(axis=3, name='Bn1')(X)
      X = Activation('relu')(X)
      X = MaxPooling2D((3,3), strides=2, name='Max1')(X)
      X = Dropout(0.5)(X)
      # Conv layer 2
      X = Conv2D(256, (3,3), padding='same', name='Conv2', kernel_initializer=initializers.GlorotUniform())(X)
      X = BatchNormalization(axis=3, name='Bn2')(X)
      X = Activation('relu')(X)
      X = MaxPooling2D((2,2), strides=2, name='Max2')(X)
      X = Dropout(0.5)(X)
      # Fully connected layer 0 
      X = Flatten()(X)
      X = Dense(4096, activation='relu', name="Fc0", kernel_initializer=initializers.GlorotUniform())(X)
      X = Dropout(0.5)(X) 
      # Fully connected layer 1 
      X = Dense(4096, activation='relu', name="Fc1", kernel_initializer=initializers.GlorotUniform())(X)
      X = Dropout(0.5)(X) 
      # Fully connected layer 2 
      X = Dense(15, activation='softmax', name="Fc2", kernel_initializer=initializers.GlorotUniform())(X)
      opt=SGD(learning_rate=0.001 , momentum=0.97)
      model = Model(inputs=X_input,outputs=X, name='AlexNet')
      model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])
      return model

alex = AlexNet()
Train_Datagen = ImageDataGenerator(rescale=1./255)
Train_Path = '/content/Augmented_Data/Train'
Train = Train_Datagen.flow_from_directory(Train_Path, target_size=(227,227), class_mode='categorical', batch_size=256)	
Test_Datagen = ImageDataGenerator(rescale=1./255)
Test_Path = '/content/Augmented_Data/Test'
Test = Test_Datagen.flow_from_directory(Test_Path, target_size=(227,227), class_mode='categorical', batch_size=256)
y_pred_test = True_val('/content/Augmented_Data/Test/')
y_pred_train = True_val('/content/Augmented_Data/Train/')
max_iter = 41
jump = 3
Test_Loss_Top1 = np.zeros((max_iter-1)//jump+1)
Test_Accuracy_Top1 = np.zeros((max_iter-1)//jump+1)
Train_Loss_Top1 = np.zeros((max_iter-1)//jump+1)
Train_Accuracy_Top1 = np.zeros((max_iter-1)//jump+1)
Test_Accuracy_Top5 = np.zeros((max_iter-1)//jump+1)
Train_Accuracy_Top5 = np.zeros((max_iter-1)//jump+1)
m = SparseTopKCategoricalAccuracy(k=5)

m = SparseTopKCategoricalAccuracy(k=5)

for k in range(1,max_iter+1,jump):
  with tf.device(tf.test.gpu_device_name()):
    alex.fit(Train,epochs=k)
    Train_Top1 = alex.evaluate(Train)
    Train_Loss_Top1[(k-1)//jump]=Train_Top1[0]
    Train_Accuracy_Top1[(k-1)//jump]=Train_Top1[1]
    Test_Top1 = alex.evaluate(Test)
    Test_Loss_Top1[(k-1)//jump]=Test_Top1[0]
    Test_Accuracy_Top1[(k-1)//jump]=Test_Top1[1]
    #Train_Top5 = alex.predict(Train)
    #m.reset_states()
    #m.update_state(y_pred_train,Train_Top5) 
    #Train_Accuracy_Top5[(k-1)//jump] = m.result().numpy()
    #Test_Top5 = alex.predict(Test)
    #m.reset_states()
    #m.update_state(y_pred_test,Test_Top5) 
    #Test_Accuracy_Top5[(k-1)//jump] = m.result().numpy()    
    #print(Test_Accuracy_Top1)
    #print(Test_Accuracy_Top5)
    #print(Test_Loss_Top1)
    #print(Train_Accuracy_Top1)
    #print(Train_Accuracy_Top5)
    #print(Train_Loss_Top1)

plot_func(Test_Accuracy_Top1,Train_Accuracy_Top1,max_iter,'/content/Accuracy_top1.png','Accuracy',"Top-1")
#plot_func(Test_Accuracy_Top5,Train_Accuracy_Top5,max_iter,'/content/Accuracy_top5.png','Accuracy',"Top-5")
plot_func(Test_Loss_Top1,Train_Loss_Top1,max_iter,'/content/Loss_top1.png','Loss',"Top-1")

"""Section 3"""

import tensorflow as tf
tf.config.experimental.set_memory_growth(tf.config.list_physical_devices('GPU')[0],True)
import numpy as np
from keras import initializers
from keras import layers,callbacks
from keras.callbacks import ModelCheckpoint
from keras.layers import Input, Dense, Activation,BatchNormalization, Flatten, Conv2D, MaxPooling2D, Dropout
from keras.models import Model
from keras.preprocessing import image
from keras.optimizers import SGD
from keras.preprocessing.image import ImageDataGenerator
from keras import metrics
from keras.metrics import SparseTopKCategoricalAccuracy 
import keras.backend as K
K.set_image_data_format("channels_last")
import glob 
import matplotlib.pyplot as plt

def True_val(File):
  counter = 0 ;
  true_pred = np.zeros([1,1])
  folders = glob.glob(f'{File}/*')
  for folder in folders:
    num_of_classes = np.size(glob.glob(f'{folder}/*.jpg'))
    val = np.ones([num_of_classes,1])*counter
    true_pred = np.concatenate((true_pred,val), axis=0)
    counter += 1
  true_pred = np.delete(true_pred,0,axis=0)
  return true_pred

def plot_func(y1,y2,max_iter,plt_file,plt_type,plt_title):
  x = np.array(range(1,max_iter+1,jump))
  plt.plot(x, y1, label = f'Test {plt_type}' , color='red', marker='o', markerfacecolor='red', markersize=5)
  plt.plot(x, y2, label = f'Train {plt_type}', color='blue' , marker='o', markerfacecolor='blue', markersize=5)
  plt.xlabel('x - epoch')
  plt.ylabel(f'{plt_type} - axis')
  plt.title(f'{plt_title}')
  plt.legend()
  plt.grid()
  plt.show()
  plt.savefig(plt_file)

def AlexNet():
  tf.config.experimental.list_logical_devices('GPU')
  tf.debugging.set_log_device_placement(True)
  with tf.device(tf.test.gpu_device_name()):
      X_input = Input((227,227,3))
      # Conv layer 0
      X = Conv2D(96,(11,11), strides=4, name="Conv0", kernel_initializer=initializers.GlorotUniform())(X_input)
      X = BatchNormalization(axis=3, name="Bn0")(X)
      X = Activation('relu')(X)
      X = MaxPooling2D((3,3), strides=2, name='Max0')(X)
      X = Dropout(0.5)(X)
      # Conv layer 1
      X = Conv2D(256,(5,5), padding='same', name='Conv1', kernel_initializer=initializers.GlorotUniform())(X)
      X = BatchNormalization(axis = 3 ,name='Bn1')(X)
      X = Activation('relu')(X)
      X = MaxPooling2D((3,3), strides=2, name='Max1')(X)
      X = Dropout(0.5)(X)
      # Conv layer 2
      X = Conv2D(384, (3,3), padding='same', name='Conv2', kernel_initializer=initializers.GlorotUniform())(X)
      X = BatchNormalization(axis=3, name='Bn2')(X)
      X = Activation('relu')(X)
      # Conv layer 3
      X = Conv2D(384, (3,3), padding='same', name='Conv3', kernel_initializer=initializers.GlorotUniform())(X)
      X = BatchNormalization(axis=3, name='Bn3')(X)
      X = Activation('relu')(X)
      # Conv layer 4
      X = Conv2D(256, (3,3), padding='same', name='Conv4')(X)
      X = BatchNormalization(axis=3, name='Bn4')(X)
      X = Activation('relu')(X) 
      X = MaxPooling2D((3,3), strides=2, name='Max4')(X)
      X = Dropout(0.5)(X)    
      # Fully connected layer 0 
      X = Flatten()(X)
      X = Dense(4096, activation='relu', name="Fc0", kernel_initializer=initializers.GlorotUniform())(X)
      X = Dropout(0.5)(X) 
      # Fully connected layer 1 
      X = Dense(4096, activation='relu', name="Fc1", kernel_initializer=initializers.GlorotUniform())(X)
      X = Dropout(0.5)(X) 
      # Fully connected layer 2 
      X = Dense(15, activation='softmax', name="Fc2", kernel_initializer=initializers.GlorotUniform())(X)
      model = Model(inputs=X_input,outputs=X, name='AlexNet')
      opt=SGD(learning_rate=0.001 , momentum=0.97)
      model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])
      return model

alex = AlexNet()
Train_Datagen = ImageDataGenerator(rescale=1./255)
Train_Path = '/content/Augmented_Data/Train'
Train = Train_Datagen.flow_from_directory(Train_Path, target_size=(227,227), class_mode='categorical', batch_size=256)	
Test_Datagen = ImageDataGenerator(rescale=1./255)
Test_Path = '/content/Augmented_Data/Test'
Test = Test_Datagen.flow_from_directory(Test_Path, target_size=(227,227), class_mode='categorical', batch_size=256)
y_pred_test = True_val('/content/Augmented_Data/Test/')
y_pred_train = True_val('/content/Augmented_Data/Train/')
max_iter = 41
jump = 3
Test_Loss_Top1 = np.zeros((max_iter-1)//jump+1)
Test_Accuracy_Top1 = np.zeros((max_iter-1)//jump+1)
Train_Loss_Top1 = np.zeros((max_iter-1)//jump+1)
Train_Accuracy_Top1 = np.zeros((max_iter-1)//jump+1)
Test_Accuracy_Top5 = np.zeros((max_iter-1)//jump+1)
Train_Accuracy_Top5 = np.zeros((max_iter-1)//jump+1)
m = SparseTopKCategoricalAccuracy(k=5)

m = SparseTopKCategoricalAccuracy(k=5)

for k in range(1,max_iter+1,jump):
  with tf.device(tf.test.gpu_device_name()):
    alex.fit(Train,epochs=k)
    Train_Top1 = alex.evaluate(Train)
    Train_Loss_Top1[(k-1)//jump]=Train_Top1[0]
    Train_Accuracy_Top1[(k-1)//jump]=Train_Top1[1]
    Test_Top1 = alex.evaluate(Test)
    Test_Loss_Top1[(k-1)//jump]=Test_Top1[0]
    Test_Accuracy_Top1[(k-1)//jump]=Test_Top1[1]
    #Train_Top5 = alex.predict(Train)
    #m.reset_states()
    #m.update_state(y_pred_train,Train_Top5) 
    #Train_Accuracy_Top5[(k-1)//jump] = m.result().numpy()
    #Test_Top5 = alex.predict(Test)
    #m.reset_states()
    #m.update_state(y_pred_test,Test_Top5) 
    #Test_Accuracy_Top5[(k-1)//jump] = m.result().numpy()    
    #print(Test_Accuracy_Top1)
    #print(Test_Accuracy_Top5)
    #print(Test_Loss_Top1)
    #print(Train_Accuracy_Top1)
    #print(Train_Accuracy_Top5)
    #print(Train_Loss_Top1)

plot_func(Test_Accuracy_Top1,Train_Accuracy_Top1,max_iter,'/content/Accuracy_top1.png','Accuracy',"Top-1")
#plot_func(Test_Accuracy_Top5,Train_Accuracy_Top5,max_iter,'/content/Accuracy_top5.png','Accuracy',"Top-5")
plot_func(Test_Loss_Top1,Train_Loss_Top1,max_iter,'/content/Loss_top1.png','Loss',"Top-1")

"""Section 4"""

import torch
import torchvision
import torchvision.models as models
import torchvision.transforms as transforms
import torch.nn as nn
import torch.optim as optim
import matplotlib.pyplot as plt

def plot_func(y1,y2,max_iter,plt_file,plt_type,plt_title):
  x = np.array(range(1,max_iter+1,jump))
  plt.plot(x, y1, label = f'Test {plt_type}' , color='red', marker='o', markerfacecolor='red', markersize=5)
  plt.plot(x, y2, label = f'Train {plt_type}', color='blue' , marker='o', markerfacecolor='blue', markersize=5)
  plt.xlabel('epoch')
  plt.ylabel(f'{plt_type}')
  plt.title(f'{plt_title}')
  if plt_type == 'Accuracy':
    plt.ylim(0, 1)
  plt.legend()
  plt.grid()
  plt.show()
  plt.savefig(plt_file)
  return

alexnet = models.alexnet(pretrained=True)
Last_layer = nn.Linear(in_features=4096, out_features=15, bias=True)
FC = list(alexnet.classifier.children())
del FC[-1]
FC.append(Last_layer)
Conv = list(alexnet.features.children())
Flat = nn.Flatten()
Conv.append(Flat)
model = Conv + FC
alexnet = nn.Sequential(*model)
for p in alexnet[0:-1].parameters():
  p.requires_grad = False
for p in alexnet[-1].parameters():
  p.requires_grad = True

device = torch.device("cuda:0")
alexnet = alexnet.to(device)
Opt = optim.SGD(alexnet[-1].parameters(), lr=0.001, momentum=0.5)
Criterion = nn.CrossEntropyLoss() 
Train_path = "/content/Data/Train/"
Test_path = "/content/Data/Test/"
Transform_Img = transforms.Compose([transforms.Resize((227,227)),transforms.ToTensor()])

Trainset  = torchvision.datasets.ImageFolder(root=Train_path,transform=Transform_Img)
Trainloader  = torch.utils.data.DataLoader(Trainset, batch_size=4, shuffle=False,  num_workers=2)
Testset  = torchvision.datasets.ImageFolder(root=Test_path,transform=Transform_Img)
Testloader   = torch.utils.data.DataLoader(Testset , batch_size=4, shuffle=False, num_workers=2) 
max_iter = 41
jump = 3
Test_Loss_Top1 = np.zeros((max_iter-1)//jump+1)
Test_Accuracy_Top1 = np.zeros((max_iter-1)//jump+1)
Test_Accuracy_Top5 = np.zeros((max_iter-1)//jump+1)
Train_Loss_Top1 = np.zeros((max_iter-1)//jump+1)
Train_Accuracy_Top1 = np.zeros((max_iter-1)//jump+1)
Train_Accuracy_Top5 = np.zeros((max_iter-1)//jump+1)

for k in range(1,max_iter,jump):
  alexnet = nn.Sequential(*model)
  alexnet = alexnet.to(device)
  for epochs in range(k):
    Sum = 0.0
    for i, data in enumerate(Trainloader, 0):
      inputs, labels = data
      inputs, labels = inputs.cuda(), labels.cuda()
      Opt.zero_grad()
      outputs = alexnet(inputs)
      Loss = Criterion(outputs, labels)
      Loss.backward()
      Opt.step()
      Sum += Loss.item()
  Total = 0
  with torch.no_grad():
    for data in Testloader:
        inputs, labels = data
        inputs, labels = inputs.cuda(), labels.cuda()
        outputs = alexnet(inputs)
        Top5 = outputs.data.topk(5,dim=1).indices
        Loss = Criterion(outputs, labels)
        _, predicted = torch.max(outputs.data, 1)
        Total += labels.size(0)
        Test_Accuracy_Top1[(k-1)//jump] += (predicted == labels).sum().item()
        for i in range(Top5.shape[0]):
          Test_Accuracy_Top5[(k-1)//jump] += (labels[i] in Top5[i])*1      
        Test_Loss_Top1[(k-1)//jump] += Loss
    Test_Accuracy_Top1[(k-1)//jump] /= Total
    Test_Accuracy_Top5[(k-1)//jump] /= Total
    Test_Loss_Top1[(k-1)//jump] /= Total
  Total = 0  
  with torch.no_grad():
    for data in Trainloader:
        inputs, labels = data
        inputs, labels = inputs.cuda(), labels.cuda()
        outputs = alexnet(inputs)
        Top5 = outputs.data.topk(5,dim=1).indices
        Loss = Criterion(outputs, labels)
        _, predicted = torch.max(outputs.data, 1)
        Total += labels.size(0)
        Train_Accuracy_Top1[(k-1)//jump] += (predicted == labels).sum().item()
        for i in range(Top5.shape[0]):
          Train_Accuracy_Top5[(k-1)//jump] += (labels[i] in Top5[i])*1     
        Train_Loss_Top1[(k-1)//jump] += Loss
    Train_Accuracy_Top1[(k-1)//jump] /= Total
    Train_Accuracy_Top5[(k-1)//jump] /= Total
    Train_Loss_Top1[(k-1)//jump] /= Total
    #print(Test_Accuracy_Top1)
    #print(Test_Accuracy_Top5)
    #print(Test_Loss_Top1)
    #print(Train_Accuracy_Top1)
    #print(Train_Accuracy_Top5)
    #print(Train_Loss_Top1)

plot_func(Test_Accuracy_Top1,Train_Accuracy_Top1,max_iter,'/content/Accuracy_top1.png','Accuracy',"Top-1")
plot_func(Test_Accuracy_Top5,Train_Accuracy_Top5,max_iter,'/content/Accuracy_top5.png','Accuracy',"Top-5")
plot_func(Test_Loss_Top1,Train_Loss_Top1,max_iter,'/content/Loss_top1.png','Loss',"Top-1")

"""Section 5"""

import torch
import torchvision
import torchvision.models as models
import torchvision.transforms as transforms
import torch.nn as nn
import torch.optim as optim
import matplotlib.pyplot as plt

def plot_func(y1,y2,max_iter,plt_file,plt_type,plt_title):
  x = np.array(range(1,max_iter+1,jump))
  plt.plot(x, y1, label = f'Test {plt_type}' , color='red', marker='o', markerfacecolor='red', markersize=5)
  plt.plot(x, y2, label = f'Train {plt_type}', color='blue' , marker='o', markerfacecolor='blue', markersize=5)
  plt.xlabel('epoch')
  plt.ylabel(f'{plt_type}')
  plt.title(f'{plt_title}')
  if plt_type == 'Accuracy':
    plt.ylim(0, 1)
  plt.legend()
  plt.grid()
  plt.show()
  plt.savefig(plt_file)
  return

alexnet = models.alexnet(pretrained=True)
Last_layer = nn.Linear(in_features=4096, out_features=15, bias=True)
FC = list(alexnet.classifier.children())
del FC[-1]
FC.append(Last_layer)
Conv = list(alexnet.features.children())
Flat = nn.Flatten()
Conv.append(Flat)
model = Conv + FC
alexnet = nn.Sequential(*model)
for p in alexnet.parameters():
  p.requires_grad = True

device = torch.device("cuda:0")
alexnet = alexnet.to(device)
Opt = optim.SGD(alexnet.parameters(), lr=0.0005, momentum=0.5)
Criterion = nn.CrossEntropyLoss()
Train_path = "/content/Data/Train/"
Test_path = "/content/Data/Test/"
Transform_Img = transforms.Compose([transforms.Resize((227,227)),transforms.ToTensor()])
Trainset  = torchvision.datasets.ImageFolder(root=Train_path,transform=Transform_Img)
Trainloader  = torch.utils.data.DataLoader(Trainset, batch_size=4, shuffle=False,  num_workers=2)
Testset  = torchvision.datasets.ImageFolder(root=Test_path,transform=Transform_Img)
Testloader   = torch.utils.data.DataLoader(Testset , batch_size=4, shuffle=False, num_workers=2)
max_iter = 41
jump = 3
Test_Loss_Top1 = np.zeros((max_iter-1)//jump+1)
Test_Accuracy_Top1 = np.zeros((max_iter-1)//jump+1)
Test_Accuracy_Top5 = np.zeros((max_iter-1)//jump+1)
Train_Loss_Top1 = np.zeros((max_iter-1)//jump+1)
Train_Accuracy_Top1 = np.zeros((max_iter-1)//jump+1)
Train_Accuracy_Top5 = np.zeros((max_iter-1)//jump+1)

for k in range(1,max_iter,jump):
  alexnet = nn.Sequential(*model)
  alexnet = alexnet.to(device)
  for epochs in range(k):
    Sum = 0.0
    for i, data in enumerate(Trainloader, 0):
      inputs, labels = data
      inputs, labels = inputs.cuda(), labels.cuda()
      Opt.zero_grad()
      outputs = alexnet(inputs)
      Loss = Criterion(outputs, labels)
      Loss.backward()
      Opt.step()
      Sum += Loss.item()
  Total = 0
  with torch.no_grad():
    for data in Testloader:
        inputs, labels = data
        inputs, labels = inputs.cuda(), labels.cuda()
        outputs = alexnet(inputs)
        Top5 = outputs.data.topk(5,dim=1).indices
        Loss = Criterion(outputs, labels)
        _, predicted = torch.max(outputs.data, 1)
        Total += labels.size(0)
        Test_Accuracy_Top1[(k-1)//jump] += (predicted == labels).sum().item()
        for i in range(Top5.shape[0]):
          Test_Accuracy_Top5[(k-1)//jump] += (labels[i] in Top5[i])*1      
        Test_Loss_Top1[(k-1)//jump] += Loss
    Test_Accuracy_Top1[(k-1)//jump] /= Total
    Test_Accuracy_Top5[(k-1)//jump] /= Total
    Test_Loss_Top1[(k-1)//jump] /= Total
  Total = 0  
  with torch.no_grad():
    for data in Trainloader:
        inputs, labels = data
        inputs, labels = inputs.cuda(), labels.cuda()
        outputs = alexnet(inputs)
        Top5 = outputs.data.topk(5,dim=1).indices
        Loss = Criterion(outputs, labels)
        _, predicted = torch.max(outputs.data, 1)
        Total += labels.size(0)
        Train_Accuracy_Top1[(k-1)//jump] += (predicted == labels).sum().item()
        for i in range(Top5.shape[0]):
          Train_Accuracy_Top5[(k-1)//jump] += (labels[i] in Top5[i])*1     
        Train_Loss_Top1[(k-1)//jump] += Loss
    Train_Accuracy_Top1[(k-1)//jump] /= Total
    Train_Accuracy_Top5[(k-1)//jump] /= Total
    Train_Loss_Top1[(k-1)//jump] /= Total
    #print(Test_Accuracy_Top1)
    #print(Test_Accuracy_Top5)
    #print(Test_Loss_Top1)
    #print(Train_Accuracy_Top1)
    #print(Train_Accuracy_Top5)
    #print(Train_Loss_Top1)

plot_func(Test_Accuracy_Top1,Train_Accuracy_Top1,max_iter,'/content/Accuracy_top1.png','Accuracy',"Top-1")
plot_func(Test_Accuracy_Top5,Train_Accuracy_Top5,max_iter,'/content/Accuracy_top5.png','Accuracy',"Top-5")
plot_func(Test_Loss_Top1,Train_Loss_Top1,max_iter,'/content/Loss_top1.png','Loss',"Top-1")